{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c671a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\st-gcn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data_loader() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5408/355308957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mdata_stop_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"hit_stopword\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mdict_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"dict\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_stop_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data_loader() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "def read_dict(voc_dict_path):\n",
    "    voc_dict = {}\n",
    "    dict_list = open(voc_dict_path).readlines()\n",
    "    for item in dict_list:\n",
    "        item = item.split(\",\")\n",
    "        voc_dict[item[0]] = int(item[1].strip())\n",
    "    return voc_dict\n",
    "\n",
    "def load_data(data_path,data_stop_path):\n",
    "    data_list = open(data_path).readlines()[1:]\n",
    "    stops_word = open(data_stop_path).readlines()\n",
    "    stops_word = [line.strip() for line in stops_word]\n",
    "    stops_word.append(\" \")\n",
    "    stops_word.append(\"\\n\")\n",
    "    voc_dict = {}\n",
    "    data = []\n",
    "    max_len_seq = 0\n",
    "    np.random.shuffle(data_list)\n",
    "    for item in data_list[:1000]:\n",
    "        label = item[0]\n",
    "        content = item[2:].strip()\n",
    "        seg_list = jieba.cut(content, cut_all=False)\n",
    "        seg_res = []\n",
    "        for seg_item in seg_list:\n",
    "            if seg_item in stops_word:\n",
    "                continue\n",
    "            seg_res.append(seg_item)\n",
    "            if seg_item in voc_dict.keys():\n",
    "                voc_dict[seg_item] = voc_dict[seg_item] + 1\n",
    "            else:\n",
    "                voc_dict[seg_item] = 1\n",
    "        if len(seg_res) > max_len_seq:\n",
    "            max_len_seq = len(seg_res)\n",
    "        data.append([label, seg_res])\n",
    "    return data, max_len_seq\n",
    "\n",
    "\n",
    "class text_ClS(Dataset):\n",
    "    def __init__(self, voc_dict_path, data_path, data_stop_path, max_len_seq=None):\n",
    "        self.data_path = data_path\n",
    "        self.data_stop_path = data_stop_path\n",
    "        self.voc_dict = read_dict(voc_dict_path)\n",
    "        self.data, self.max_seq_len = \\\n",
    "            load_data(self.data_path, self.data_stop_path)\n",
    "        if max_len_seq is not None:\n",
    "            self.max_seq_len = max_len_seq\n",
    "        np.random.shuffle(self.data)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self.data[item]\n",
    "        label = int(data[0])\n",
    "        word_list = data[1]\n",
    "        input_idx = []\n",
    "        for word in word_list:\n",
    "            if word in self.voc_dict.keys():\n",
    "                input_idx.append(self.voc_dict[word])\n",
    "            else:\n",
    "                input_idx.append(self.voc_dict[\"<UNK>\"])\n",
    "        if len(input_idx) < self.max_seq_len:\n",
    "            input_idx += [self.voc_dict[\"<PAD>\"]\n",
    "                          for _ in range(self.max_seq_len - len(input_idx))]\n",
    "        data = np.array(input_idx)\n",
    "        return label, data\n",
    "\n",
    "def data_loader(dataset, config):\n",
    "    return DataLoader(dataset, batch_size=config.batch_size, shuffle=config.is_shuffle)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"weibo_senti_100k.csv\"\n",
    "    data_stop_path = \"hit_stopword\"\n",
    "    dict_path = \"dict\"\n",
    "    train_dataloader = data_loader(data_path, data_stop_path, dict_path)\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        print(batch[1].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f9a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
